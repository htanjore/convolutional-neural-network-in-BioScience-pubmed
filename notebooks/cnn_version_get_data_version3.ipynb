{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os.path\n",
    "import requests\n",
    "import re\n",
    "pd.options.display.max_rows = 1500\n",
    "pd.options.display.max_columns = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(search_for, filename):\n",
    "    \"\"\" 1. This function takes two arguments a) search item, b)filename to be saved\n",
    "        2. Searches the pubmed that gives keys a) query key and b) webenv key\n",
    "        3. Fetches files from the server using the keys and saves it as a txt file of the xml output \n",
    "        and prints the number of records in total\"\"\"\n",
    "    url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&usehistory=y&retmax=99999&term=\"+search_for\n",
    "    response = requests.get(url)\n",
    "    search = BeautifulSoup(response.content, 'xml')\n",
    "    total_ids_search = int(search.find('Count').text)\n",
    "    webenv = search.find('WebEnv').text\n",
    "    query_key = search.find('QueryKey').text\n",
    "    get_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&retmode=xml&query_key=1&webenv=\"+webenv\n",
    "    for item in range(0, total_ids_search, 100000):\n",
    "        get = get_url+\"&retstart=\"+str(item)\n",
    "        #get = get_url+\"&retmax=\"+number+\"&retstart=\"+str(item)\n",
    "        get_response = requests.post(get)\n",
    "        file = open(\"../data/\"+filename+'.txt', 'w') # location of text file\n",
    "        file.write(get_response.text) # saves the results into a txt file from get_response\n",
    "        file.close()\n",
    "        print(\"Total Number of records found :\"+str(total_ids_search))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(filename, tocsv):\n",
    "    \"\"\" 1.This function reads filename, that the user provided with an extension .txt generated from pubmed after get_data(search_for, filename) function.\n",
    "        2.Then parses the xml file and creates a lists of PMID, Article_title, ISOAbbreviation, Journal_title,\n",
    "         Abstract, Journal_Country,Published_year, Keyword_list,publication_type,Medlinecitation,pubmed_year,Affiliation\n",
    "        3.Take the above list and creates a dataframe and returns a dataframe\n",
    "        4.Finally the datafrane is saved into a csv file\"\"\"\n",
    "    pubmed_results = open('../data/'+filename,'r')\n",
    "    contents = pubmed_results.read()\n",
    "    soup = BeautifulSoup(contents, 'xml')\n",
    "    root = soup.find_all('PubmedArticle')\n",
    "\n",
    "    notuseful_list = ['Research Support', \"U.S. Gov't\",\"Non-U.S. Gov't\",\"Research Support, Non-U.S. Gov't\",\n",
    "           \"Research Support, N.I.H., Extramural\", \"Research Support, U.S. Gov't, Non-P.H.S.\",\n",
    "           \"Research Support, N.I.H., Extramural,Research Support, U.S. Gov't, Non-P.H.S.\" ,\n",
    "           \"Research Support, N.I.H., Intramural\", \"Research Support, U.S. Gov't, P.H.S.\" ] \n",
    "\n",
    "\n",
    "    PMID = []\n",
    "    year=[]\n",
    "    ISO = []\n",
    "    Article_title = []\n",
    "    Journal_Country=[]\n",
    "    Journal_title=[]\n",
    "    abstract = []\n",
    "    keywords=[]\n",
    "    Medlinecitation = []\n",
    "    pubmed_year =[]\n",
    "\n",
    "    for item in root:\n",
    "        pmid =  item.find('PMID')\n",
    "        pmid_text= pmid.text\n",
    "        PMID.append(pmid_text)\n",
    "        iso_abbreviation = item.find('ISOAbbreviation')\n",
    "        iso_abbreviation_text = iso_abbreviation.text\n",
    "        ISO.append(iso_abbreviation_text)\n",
    "        title = item.find('ArticleTitle')\n",
    "        title_text = title.text\n",
    "        Article_title.append(title_text)\n",
    "\n",
    "    for item in root:\n",
    "        if item is not None:\n",
    "            journal = item.find('Journal')\n",
    "            journal_name = journal.find_all('Title')\n",
    "            for item in journal_name:\n",
    "                journal_name_list = item.string\n",
    "                Journal_title.append(journal_name_list)\n",
    "        else:\n",
    "             Journal_title.append(None)  \n",
    "\n",
    "    all_Year_info =[]    \n",
    "    for item in root:\n",
    "        year_pub =  item.find_all('PubDate')\n",
    "        year_pub_text = year_pub[0].text\n",
    "        all_Year_info.append(year_pub_text)\n",
    "        s = ''.join(all_Year_info)\n",
    "    for item in re.findall('(\\d{4})', s):\n",
    "        year.append(item.strip())\n",
    "\n",
    "    for item in root:\n",
    "        year_pub =  item.find(PubStatus=\"pubmed\")\n",
    "        if year_pub is not None:\n",
    "            year1 =  year_pub.find_all('Year')\n",
    "            for i in year1:\n",
    "                pubmed_year.append(i.text)\n",
    "\n",
    "    pubtype=[]\n",
    "    for item in root:\n",
    "        pub = item.find('PublicationTypeList')\n",
    "        if pub is not None:\n",
    "            pub_lst=[]\n",
    "            pubtype_list = pub.find_all('PublicationType')\n",
    "            for item in pubtype_list:\n",
    "                pubtype_text = item.text\n",
    "                pub_lst.append(pubtype_text)\n",
    "            pub_lst = [x for x in pub_lst if x.strip() not in notuseful_list]\n",
    "            pubs_join= ','.join(pub_lst)\n",
    "            pubtype.append(pubs_join)\n",
    "        else:\n",
    "            pubtype.append(None)      \n",
    "\n",
    "    for item in root:\n",
    "        journal_country = item.find('MedlineJournalInfo')\n",
    "        if journal_country is not None:\n",
    "            country_list = journal_country.find_all('Country')\n",
    "            for item in country_list:\n",
    "                country_list=item.text\n",
    "                Journal_Country.append(country_list)\n",
    "        else:\n",
    "            Journal_Country.append(None)\n",
    "\n",
    "    for item in root:\n",
    "        abstract_text = item.find('Abstract')\n",
    "        if abstract_text is not None:\n",
    "            text = abstract_text.find_all('AbstractText')\n",
    "            lst = []\n",
    "            for item in text:\n",
    "                lst.append(item.text)\n",
    "            lst_join='\\n'.join(lst)\n",
    "            abstract.append(lst_join)\n",
    "        else:\n",
    "             abstract.append(None) \n",
    "\n",
    "    for item in root:\n",
    "        keyword_text=item.find('KeywordList')\n",
    "        if keyword_text is not None:\n",
    "            key=[]\n",
    "            keyword_text_list=keyword_text.find_all('Keyword')\n",
    "            for item in keyword_text_list:\n",
    "                keyword_text=item.text\n",
    "                key.append(keyword_text)\n",
    "            keys_join=','.join(key)\n",
    "            keywords.append(keys_join)\n",
    "        else:\n",
    "            keywords.append(None)\n",
    "\n",
    "    for item in soup.find_all('MedlineCitation'):\n",
    "        status = item.get('Status')\n",
    "        Medlinecitation.append(status)    \n",
    "\n",
    "    affiliation=[] \n",
    "    for item in root:\n",
    "        abstract_text = item.find('AuthorList')\n",
    "        if abstract_text is not None:\n",
    "            text = abstract_text.find_all('Affiliation')\n",
    "            lst = []\n",
    "            for item in text:\n",
    "                lst.append(item.text)\n",
    "            lst_join='\\n'.join(lst).replace(\"\\n\",\"\")\n",
    "            affiliation.append(lst_join)\n",
    "        else:\n",
    "            affiliation.append(None)\n",
    "            \n",
    "    dict_columns = {'PMID': PMID,\n",
    "       'Title': Article_title,\n",
    "         'ISOAbbreviation': ISO,\n",
    "       'journal_title':Journal_title,\n",
    "         'Abstract':abstract,\n",
    "         'Journalinfo_country': Journal_Country,\n",
    "          'Published_year':year,\n",
    "           'Keyword_list':keywords,\n",
    "          'publication_type':pubtype,\n",
    "          'medline_citation':Medlinecitation,\n",
    "          \"pubmed_year\":pubmed_year,\n",
    "          \"Affiliation\":affiliation}\n",
    "\n",
    "    df =pd.DataFrame.from_dict(dict_columns, orient='index').transpose()\n",
    "    df.to_csv('../data/'+tocsv+'.csv',index=False)\n",
    "    print(\"Number of articles :\"+str(len(root)))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of records found :4331\n",
      "Number of articles :4331\n"
     ]
    }
   ],
   "source": [
    "#get_data(search_for, filename) # search anything in pubmed AND prints number of records\n",
    "get_data('convolutional neural network','pubmed_result')\n",
    "# get_dataframe(filename, tocsv) #give file name from get_data with txt extension like pubmed_result.txt and assign the function to a variable\n",
    "cnn=get_dataframe('pubmed_result.txt', 'cnn_pubmed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>Title</th>\n",
       "      <th>ISOAbbreviation</th>\n",
       "      <th>journal_title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Journalinfo_country</th>\n",
       "      <th>Published_year</th>\n",
       "      <th>Keyword_list</th>\n",
       "      <th>publication_type</th>\n",
       "      <th>medline_citation</th>\n",
       "      <th>pubmed_year</th>\n",
       "      <th>Affiliation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31752016</td>\n",
       "      <td>The Neyman Pearson detection of microsaccades ...</td>\n",
       "      <td>J Vis</td>\n",
       "      <td>Journal of vision</td>\n",
       "      <td>Despite the fact that the velocity threshold m...</td>\n",
       "      <td>United States</td>\n",
       "      <td>2019</td>\n",
       "      <td>None</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>In-Data-Review</td>\n",
       "      <td>2019</td>\n",
       "      <td>School of Biomedical Engineering, University o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31751272</td>\n",
       "      <td>Semi-Supervised Image Dehazing.</td>\n",
       "      <td>IEEE Trans Image Process</td>\n",
       "      <td>IEEE transactions on image processing : a publ...</td>\n",
       "      <td>We present an effective semi-supervised learni...</td>\n",
       "      <td>United States</td>\n",
       "      <td>2019</td>\n",
       "      <td>None</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>Publisher</td>\n",
       "      <td>2019</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31751269</td>\n",
       "      <td>Progressively trained convolutional neural net...</td>\n",
       "      <td>IEEE Trans Med Imaging</td>\n",
       "      <td>IEEE transactions on medical imaging</td>\n",
       "      <td>Deep learning-based methods for deformable ima...</td>\n",
       "      <td>United States</td>\n",
       "      <td>2019</td>\n",
       "      <td>None</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>Publisher</td>\n",
       "      <td>2019</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31751268</td>\n",
       "      <td>De-smokeGCN: Generative Cooperative Networks f...</td>\n",
       "      <td>IEEE Trans Med Imaging</td>\n",
       "      <td>IEEE transactions on medical imaging</td>\n",
       "      <td>Surgical smoke removal algorithms can improve ...</td>\n",
       "      <td>United States</td>\n",
       "      <td>2019</td>\n",
       "      <td>None</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>Publisher</td>\n",
       "      <td>2019</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31751239</td>\n",
       "      <td>Unsupervised Deep Contrast Enhancement with Po...</td>\n",
       "      <td>IEEE Trans Image Process</td>\n",
       "      <td>IEEE transactions on image processing : a publ...</td>\n",
       "      <td>Various power-constrained contrast enhance-men...</td>\n",
       "      <td>United States</td>\n",
       "      <td>2019</td>\n",
       "      <td>None</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>Publisher</td>\n",
       "      <td>2019</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PMID                                              Title  \\\n",
       "0  31752016  The Neyman Pearson detection of microsaccades ...   \n",
       "1  31751272                    Semi-Supervised Image Dehazing.   \n",
       "2  31751269  Progressively trained convolutional neural net...   \n",
       "3  31751268  De-smokeGCN: Generative Cooperative Networks f...   \n",
       "4  31751239  Unsupervised Deep Contrast Enhancement with Po...   \n",
       "\n",
       "            ISOAbbreviation  \\\n",
       "0                     J Vis   \n",
       "1  IEEE Trans Image Process   \n",
       "2    IEEE Trans Med Imaging   \n",
       "3    IEEE Trans Med Imaging   \n",
       "4  IEEE Trans Image Process   \n",
       "\n",
       "                                       journal_title  \\\n",
       "0                                  Journal of vision   \n",
       "1  IEEE transactions on image processing : a publ...   \n",
       "2               IEEE transactions on medical imaging   \n",
       "3               IEEE transactions on medical imaging   \n",
       "4  IEEE transactions on image processing : a publ...   \n",
       "\n",
       "                                            Abstract Journalinfo_country  \\\n",
       "0  Despite the fact that the velocity threshold m...       United States   \n",
       "1  We present an effective semi-supervised learni...       United States   \n",
       "2  Deep learning-based methods for deformable ima...       United States   \n",
       "3  Surgical smoke removal algorithms can improve ...       United States   \n",
       "4  Various power-constrained contrast enhance-men...       United States   \n",
       "\n",
       "  Published_year Keyword_list publication_type medline_citation pubmed_year  \\\n",
       "0           2019         None  Journal Article   In-Data-Review        2019   \n",
       "1           2019         None  Journal Article        Publisher        2019   \n",
       "2           2019         None  Journal Article        Publisher        2019   \n",
       "3           2019         None  Journal Article        Publisher        2019   \n",
       "4           2019         None  Journal Article        Publisher        2019   \n",
       "\n",
       "                                         Affiliation  \n",
       "0  School of Biomedical Engineering, University o...  \n",
       "1                                                     \n",
       "2                                                     \n",
       "3                                                     \n",
       "4                                                     "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
