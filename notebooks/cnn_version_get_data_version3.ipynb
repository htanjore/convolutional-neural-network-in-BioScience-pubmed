{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os.path\n",
    "import requests\n",
    "import re\n",
    "pd.options.display.max_rows = 1500\n",
    "pd.options.display.max_columns = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(search_for, filename):\n",
    "    \"\"\" 1. This function takes two arguments a) search item, b)filename to be saved\n",
    "        2. Searches the pubmed that gives keys a) query key and b) webenv key\n",
    "        3. Fetches files from the server using the keys and saves it as a txt file of the xml output \n",
    "        and prints the number of records in total\"\"\"\n",
    "    url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&usehistory=y&retmax=99999&term=\"+search_for\n",
    "    response = requests.get(url)\n",
    "    search = BeautifulSoup(response.content, 'xml')\n",
    "    total_ids_search = int(search.find('Count').text)\n",
    "    webenv = search.find('WebEnv').text\n",
    "    query_key = search.find('QueryKey').text\n",
    "    get_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&retmode=xml&query_key=1&webenv=\"+webenv\n",
    "    for item in range(0, total_ids_search, 100000):\n",
    "        get = get_url+\"&retstart=\"+str(item)\n",
    "        #get = get_url+\"&retmax=\"+number+\"&retstart=\"+str(item)\n",
    "        get_response = requests.post(get)\n",
    "        file = open(\"../data/\"+filename+'.txt', 'w') # location of text file\n",
    "        file.write(get_response.text) # saves the results into a txt file from get_response\n",
    "        file.close()\n",
    "        print(\"Total Number of records found :\"+str(total_ids_search))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(filename, tocsv):\n",
    "    \"\"\" 1.This function reads filename, that the user provided with an extension .txt generated from pubmed after get_data(search_for, filename) function.\n",
    "        2.Then parses the xml file and creates a lists of PMID, Article_title, ISOAbbreviation, Journal_title,\n",
    "         Abstract, Journal_Country,Published_year, Keyword_list,publication_type,Medlinecitation,pubmed_year,Affiliation\n",
    "        3.Take the above list and creates a dataframe and returns a dataframe\n",
    "        4.Finally the datafrane is saved into a csv file\"\"\"\n",
    "    pubmed_results = open('../data/'+filename,'r')\n",
    "    contents = pubmed_results.read()\n",
    "    soup = BeautifulSoup(contents, 'xml')\n",
    "    root = soup.find_all('PubmedArticle')\n",
    "\n",
    "    notuseful_list = ['Research Support', \"U.S. Gov't\",\"Non-U.S. Gov't\",\"Research Support, Non-U.S. Gov't\",\n",
    "           \"Research Support, N.I.H., Extramural\", \"Research Support, U.S. Gov't, Non-P.H.S.\",\n",
    "           \"Research Support, N.I.H., Extramural,Research Support, U.S. Gov't, Non-P.H.S.\" ,\n",
    "           \"Research Support, N.I.H., Intramural\", \"Research Support, U.S. Gov't, P.H.S.\" ] \n",
    "\n",
    "\n",
    "    PMID = []\n",
    "    year=[]\n",
    "    ISO = []\n",
    "    Article_title = []\n",
    "    Journal_Country=[]\n",
    "    Journal_title=[]\n",
    "    abstract = []\n",
    "    keywords=[]\n",
    "    Medlinecitation = []\n",
    "    pubmed_year =[]\n",
    "\n",
    "    for item in root:\n",
    "        pmid =  item.find('PMID')\n",
    "        pmid_text= pmid.text\n",
    "        PMID.append(pmid_text)\n",
    "        iso_abbreviation = item.find('ISOAbbreviation')\n",
    "        iso_abbreviation_text = iso_abbreviation.text\n",
    "        ISO.append(iso_abbreviation_text)\n",
    "        title = item.find('ArticleTitle')\n",
    "        title_text = title.text\n",
    "        Article_title.append(title_text)\n",
    "\n",
    "    for item in root:\n",
    "        if item is not None:\n",
    "            journal = item.find('Journal')\n",
    "            journal_name = journal.find_all('Title')\n",
    "            for item in journal_name:\n",
    "                journal_name_list = item.string\n",
    "                Journal_title.append(journal_name_list)\n",
    "        else:\n",
    "             Journal_title.append(None)  \n",
    "\n",
    "    all_Year_info =[]    \n",
    "    for item in root:\n",
    "        year_pub =  item.find_all('PubDate')\n",
    "        year_pub_text = year_pub[0].text\n",
    "        all_Year_info.append(year_pub_text)\n",
    "        s = ''.join(all_Year_info)\n",
    "    for item in re.findall('(\\d{4})', s):\n",
    "        year.append(item.strip())\n",
    "\n",
    "    for item in root:\n",
    "        year_pub =  item.find(PubStatus=\"pubmed\")\n",
    "        if year_pub is not None:\n",
    "            year1 =  year_pub.find_all('Year')\n",
    "            for i in year1:\n",
    "                pubmed_year.append(i.text)\n",
    "\n",
    "    pubtype=[]\n",
    "    for item in root:\n",
    "        pub = item.find('PublicationTypeList')\n",
    "        if pub is not None:\n",
    "            pub_lst=[]\n",
    "            pubtype_list = pub.find_all('PublicationType')\n",
    "            for item in pubtype_list:\n",
    "                pubtype_text = item.text\n",
    "                pub_lst.append(pubtype_text)\n",
    "            pub_lst = [x for x in pub_lst if x.strip() not in notuseful_list]\n",
    "            pubs_join= ','.join(pub_lst)\n",
    "            pubtype.append(pubs_join)\n",
    "        else:\n",
    "            pubtype.append(None)      \n",
    "\n",
    "    for item in root:\n",
    "        journal_country = item.find('MedlineJournalInfo')\n",
    "        if journal_country is not None:\n",
    "            country_list = journal_country.find_all('Country')\n",
    "            for item in country_list:\n",
    "                country_list=item.text\n",
    "                Journal_Country.append(country_list)\n",
    "        else:\n",
    "            Journal_Country.append(None)\n",
    "\n",
    "    for item in root:\n",
    "        abstract_text = item.find('Abstract')\n",
    "        if abstract_text is not None:\n",
    "            text = abstract_text.find_all('AbstractText')\n",
    "            lst = []\n",
    "            for item in text:\n",
    "                lst.append(item.text)\n",
    "            lst_join='\\n'.join(lst)\n",
    "            abstract.append(lst_join)\n",
    "        else:\n",
    "             abstract.append(None) \n",
    "\n",
    "    for item in root:\n",
    "        keyword_text=item.find('KeywordList')\n",
    "        if keyword_text is not None:\n",
    "            key=[]\n",
    "            keyword_text_list=keyword_text.find_all('Keyword')\n",
    "            for item in keyword_text_list:\n",
    "                keyword_text=item.text\n",
    "                key.append(keyword_text)\n",
    "            keys_join=','.join(key)\n",
    "            keywords.append(keys_join)\n",
    "        else:\n",
    "            keywords.append(None)\n",
    "\n",
    "    for item in soup.find_all('MedlineCitation'):\n",
    "        status = item.get('Status')\n",
    "        Medlinecitation.append(status)    \n",
    "\n",
    "    affiliation=[] \n",
    "    for item in root:\n",
    "        abstract_text = item.find('AuthorList')\n",
    "        if abstract_text is not None:\n",
    "            text = abstract_text.find_all('Affiliation')\n",
    "            lst = []\n",
    "            for item in text:\n",
    "                lst.append(item.text)\n",
    "            lst_join='\\n'.join(lst).replace(\"\\n\",\"\")\n",
    "            affiliation.append(lst_join)\n",
    "        else:\n",
    "            affiliation.append(None)\n",
    "            \n",
    "    dict_columns = {'PMID': PMID,\n",
    "       'Title': Article_title,\n",
    "         'ISOAbbreviation': ISO,\n",
    "       'journal_title':Journal_title,\n",
    "         'Abstract':abstract,\n",
    "         'Journalinfo_country': Journal_Country,\n",
    "          'Published_year':year,\n",
    "           'Keyword_list':keywords,\n",
    "          'publication_type':pubtype,\n",
    "          'medline_citation':Medlinecitation,\n",
    "          \"pubmed_year\":pubmed_year,\n",
    "          \"Affiliation\":affiliation}\n",
    "\n",
    "    df =pd.DataFrame.from_dict(dict_columns, orient='index').transpose()\n",
    "    df.to_csv('../data/'+tocsv+'.csv',index=False)\n",
    "    print(\"Number of articles :\"+str(len(root)))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of records found :4319\n",
      "Number of articles :4319\n"
     ]
    }
   ],
   "source": [
    "#get_data(search_for, filename) # search anything in pubmed AND prints number of records\n",
    "get_data('convolutional neural network','pubmed_result')\n",
    "# get_dataframe(filename, tocsv) #give file name from get_data with txt extension like pubmed_result.txt and assign the function to a variable\n",
    "cnn=get_dataframe('pubmed_result.txt', 'cnn_pubmed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>Title</th>\n",
       "      <th>ISOAbbreviation</th>\n",
       "      <th>journal_title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Journalinfo_country</th>\n",
       "      <th>Published_year</th>\n",
       "      <th>Keyword_list</th>\n",
       "      <th>publication_type</th>\n",
       "      <th>medline_citation</th>\n",
       "      <th>pubmed_year</th>\n",
       "      <th>Affiliation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31747632</td>\n",
       "      <td>Diabetic retinopathy detection using red lesio...</td>\n",
       "      <td>Comput. Biol. Med.</td>\n",
       "      <td>Computers in biology and medicine</td>\n",
       "      <td>Detecting the early signs of diabetic retinopa...</td>\n",
       "      <td>United States</td>\n",
       "      <td>2019</td>\n",
       "      <td>Convolutional neural networks,Deep learning,Di...</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>Publisher</td>\n",
       "      <td>2019</td>\n",
       "      <td>Department of Control and Automation Engineeri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31746961</td>\n",
       "      <td>Protein Docking Model Evaluation by 3D Deep Co...</td>\n",
       "      <td>Bioinformatics</td>\n",
       "      <td>Bioinformatics (Oxford, England)</td>\n",
       "      <td>Many important cellular processes involve phys...</td>\n",
       "      <td>England</td>\n",
       "      <td>2019</td>\n",
       "      <td>None</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>Publisher</td>\n",
       "      <td>2019</td>\n",
       "      <td>Department of Computer Science, Purdue Univers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31746687</td>\n",
       "      <td>Lymph Node Metastasis Prediction from Primary ...</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>Background Deep learning (DL) algorithms are g...</td>\n",
       "      <td>United States</td>\n",
       "      <td>2019</td>\n",
       "      <td>None</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>Publisher</td>\n",
       "      <td>2019</td>\n",
       "      <td>From the Sino-German Tongji-Caritas Research C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31745764</td>\n",
       "      <td>Contamination source identification in water d...</td>\n",
       "      <td>Environ Sci Pollut Res Int</td>\n",
       "      <td>Environmental science and pollution research i...</td>\n",
       "      <td>Contamination source identification (CSI) is s...</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2019</td>\n",
       "      <td>Complaint delay time,Consumer complaints,Conta...</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>Publisher</td>\n",
       "      <td>2019</td>\n",
       "      <td>College of Environmental Science and Engineeri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31744127</td>\n",
       "      <td>Sport-Related Human Activity Detection and Rec...</td>\n",
       "      <td>Sensors (Basel)</td>\n",
       "      <td>Sensors (Basel, Switzerland)</td>\n",
       "      <td>As an active research field, sport-related act...</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>2019</td>\n",
       "      <td>convolutional neural network,interval generati...</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>In-Process</td>\n",
       "      <td>2019</td>\n",
       "      <td>South China University of Technology, Guangzho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PMID                                              Title  \\\n",
       "0  31747632  Diabetic retinopathy detection using red lesio...   \n",
       "1  31746961  Protein Docking Model Evaluation by 3D Deep Co...   \n",
       "2  31746687  Lymph Node Metastasis Prediction from Primary ...   \n",
       "3  31745764  Contamination source identification in water d...   \n",
       "4  31744127  Sport-Related Human Activity Detection and Rec...   \n",
       "\n",
       "              ISOAbbreviation  \\\n",
       "0          Comput. Biol. Med.   \n",
       "1              Bioinformatics   \n",
       "2                   Radiology   \n",
       "3  Environ Sci Pollut Res Int   \n",
       "4             Sensors (Basel)   \n",
       "\n",
       "                                       journal_title  \\\n",
       "0                  Computers in biology and medicine   \n",
       "1                   Bioinformatics (Oxford, England)   \n",
       "2                                          Radiology   \n",
       "3  Environmental science and pollution research i...   \n",
       "4                       Sensors (Basel, Switzerland)   \n",
       "\n",
       "                                            Abstract Journalinfo_country  \\\n",
       "0  Detecting the early signs of diabetic retinopa...       United States   \n",
       "1  Many important cellular processes involve phys...             England   \n",
       "2  Background Deep learning (DL) algorithms are g...       United States   \n",
       "3  Contamination source identification (CSI) is s...             Germany   \n",
       "4  As an active research field, sport-related act...         Switzerland   \n",
       "\n",
       "  Published_year                                       Keyword_list  \\\n",
       "0           2019  Convolutional neural networks,Deep learning,Di...   \n",
       "1           2019                                               None   \n",
       "2           2019                                               None   \n",
       "3           2019  Complaint delay time,Consumer complaints,Conta...   \n",
       "4           2019  convolutional neural network,interval generati...   \n",
       "\n",
       "  publication_type medline_citation pubmed_year  \\\n",
       "0  Journal Article        Publisher        2019   \n",
       "1  Journal Article        Publisher        2019   \n",
       "2  Journal Article        Publisher        2019   \n",
       "3  Journal Article        Publisher        2019   \n",
       "4  Journal Article       In-Process        2019   \n",
       "\n",
       "                                         Affiliation  \n",
       "0  Department of Control and Automation Engineeri...  \n",
       "1  Department of Computer Science, Purdue Univers...  \n",
       "2  From the Sino-German Tongji-Caritas Research C...  \n",
       "3  College of Environmental Science and Engineeri...  \n",
       "4  South China University of Technology, Guangzho...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
