{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os.path\n",
    "import requests\n",
    "import re\n",
    "pd.options.display.max_rows = 1500\n",
    "pd.options.display.max_columns = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(search_for, filename):\n",
    "    \"\"\" 1. This function takes two arguments a) search item, b)filename to be saved\n",
    "        2. Searches the pubmed that gives keys a) query key and b) webenv key\n",
    "        3. Fetches files from the server using the keys and saves it as a txt file of the xml output \n",
    "        and prints the number of records in total\"\"\"\n",
    "    url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&usehistory=y&retmax=99999&term=\"+search_for\n",
    "    response = requests.get(url)\n",
    "    search = BeautifulSoup(response.content, 'xml')\n",
    "    total_ids_search = int(search.find('Count').text)\n",
    "    webenv = search.find('WebEnv').text\n",
    "    query_key = search.find('QueryKey').text\n",
    "    get_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&retmode=xml&query_key=1&webenv=\"+webenv\n",
    "    for item in range(0, total_ids_search, 100000):\n",
    "        get = get_url+\"&retstart=\"+str(item)\n",
    "        #get = get_url+\"&retmax=\"+number+\"&retstart=\"+str(item)\n",
    "        get_response = requests.post(get)\n",
    "        file = open(\"../data/\"+filename+'.txt', 'w') # location of text file\n",
    "        file.write(get_response.text) # saves the results into a txt file from get_response\n",
    "        file.close()\n",
    "        print(\"Total Number of records found :\"+str(total_ids_search))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(filename, tocsv):\n",
    "    \"\"\" 1.This function reads filename, that the user provided with an extension .txt generated from pubmed after get_data(search_for, filename) function.\n",
    "        2.Then parses the xml file and creates a lists of PMID, Article_title, ISOAbbreviation, Journal_title,\n",
    "         Abstract, Journal_Country,Published_year, Keyword_list,publication_type,Medlinecitation,pubmed_year,Affiliation\n",
    "        3.Take the above list and creates a dataframe and returns a dataframe\n",
    "        4.Finally the datafrane is saved into a csv file\"\"\"\n",
    "    pubmed_results = open('../data/'+filename,'r')\n",
    "    contents = pubmed_results.read()\n",
    "    soup = BeautifulSoup(contents, 'xml')\n",
    "    root = soup.find_all('PubmedArticle')\n",
    "\n",
    "    notuseful_list = ['Research Support', \"U.S. Gov't\",\"Non-U.S. Gov't\",\"Research Support, Non-U.S. Gov't\",\n",
    "           \"Research Support, N.I.H., Extramural\", \"Research Support, U.S. Gov't, Non-P.H.S.\",\n",
    "           \"Research Support, N.I.H., Extramural,Research Support, U.S. Gov't, Non-P.H.S.\" ,\n",
    "           \"Research Support, N.I.H., Intramural\", \"Research Support, U.S. Gov't, P.H.S.\" ] \n",
    "\n",
    "\n",
    "    PMID = []\n",
    "    year=[]\n",
    "    ISO = []\n",
    "    Article_title = []\n",
    "    Journal_Country=[]\n",
    "    Journal_title=[]\n",
    "    abstract = []\n",
    "    keywords=[]\n",
    "    Medlinecitation = []\n",
    "    pubmed_year =[]\n",
    "\n",
    "    for item in root:\n",
    "        pmid =  item.find('PMID')\n",
    "        pmid_text= pmid.text\n",
    "        PMID.append(pmid_text)\n",
    "        iso_abbreviation = item.find('ISOAbbreviation')\n",
    "        iso_abbreviation_text = iso_abbreviation.text\n",
    "        ISO.append(iso_abbreviation_text)\n",
    "        title = item.find('ArticleTitle')\n",
    "        title_text = title.text\n",
    "        Article_title.append(title_text)\n",
    "\n",
    "    for item in root:\n",
    "        if item is not None:\n",
    "            journal = item.find('Journal')\n",
    "            journal_name = journal.find_all('Title')\n",
    "            for item in journal_name:\n",
    "                journal_name_list = item.string\n",
    "                Journal_title.append(journal_name_list)\n",
    "        else:\n",
    "             Journal_title.append(None)  \n",
    "\n",
    "    all_Year_info =[]    \n",
    "    for item in root:\n",
    "        year_pub =  item.find_all('PubDate')\n",
    "        year_pub_text = year_pub[0].text\n",
    "        all_Year_info.append(year_pub_text)\n",
    "        s = ''.join(all_Year_info)\n",
    "    for item in re.findall('(\\d{4})', s):\n",
    "        year.append(item.strip())\n",
    "\n",
    "    for item in root:\n",
    "        year_pub =  item.find(PubStatus=\"pubmed\")\n",
    "        if year_pub is not None:\n",
    "            year1 =  year_pub.find_all('Year')\n",
    "            for i in year1:\n",
    "                pubmed_year.append(i.text)\n",
    "\n",
    "    pubtype=[]\n",
    "    for item in root:\n",
    "        pub = item.find('PublicationTypeList')\n",
    "        if pub is not None:\n",
    "            pub_lst=[]\n",
    "            pubtype_list = pub.find_all('PublicationType')\n",
    "            for item in pubtype_list:\n",
    "                pubtype_text = item.text\n",
    "                pub_lst.append(pubtype_text)\n",
    "            pub_lst = [x for x in pub_lst if x.strip() not in notuseful_list]\n",
    "            pubs_join= ','.join(pub_lst)\n",
    "            pubtype.append(pubs_join)\n",
    "        else:\n",
    "            pubtype.append(None)      \n",
    "\n",
    "    for item in root:\n",
    "        journal_country = item.find('MedlineJournalInfo')\n",
    "        if journal_country is not None:\n",
    "            country_list = journal_country.find_all('Country')\n",
    "            for item in country_list:\n",
    "                country_list=item.text\n",
    "                Journal_Country.append(country_list)\n",
    "        else:\n",
    "            Journal_Country.append(None)\n",
    "\n",
    "    for item in root:\n",
    "        abstract_text = item.find('Abstract')\n",
    "        if abstract_text is not None:\n",
    "            text = abstract_text.find_all('AbstractText')\n",
    "            lst = []\n",
    "            for item in text:\n",
    "                lst.append(item.text)\n",
    "            lst_join='\\n'.join(lst)\n",
    "            abstract.append(lst_join)\n",
    "        else:\n",
    "             abstract.append(None) \n",
    "\n",
    "    for item in root:\n",
    "        keyword_text=item.find('KeywordList')\n",
    "        if keyword_text is not None:\n",
    "            key=[]\n",
    "            keyword_text_list=keyword_text.find_all('Keyword')\n",
    "            for item in keyword_text_list:\n",
    "                keyword_text=item.text\n",
    "                key.append(keyword_text)\n",
    "            keys_join=','.join(key)\n",
    "            keywords.append(keys_join)\n",
    "        else:\n",
    "            keywords.append(None)\n",
    "\n",
    "    for item in soup.find_all('MedlineCitation'):\n",
    "        status = item.get('Status')\n",
    "        Medlinecitation.append(status)    \n",
    "\n",
    "    affiliation=[] \n",
    "    for item in root:\n",
    "        abstract_text = item.find('AuthorList')\n",
    "        if abstract_text is not None:\n",
    "            text = abstract_text.find_all('Affiliation')\n",
    "            lst = []\n",
    "            for item in text:\n",
    "                lst.append(item.text)\n",
    "            lst_join='\\n'.join(lst).replace(\"\\n\",\"\")\n",
    "            affiliation.append(lst_join)\n",
    "        else:\n",
    "            affiliation.append(None)\n",
    "            \n",
    "    dict_columns = {'PMID': PMID,\n",
    "       'Title': Article_title,\n",
    "         'ISOAbbreviation': ISO,\n",
    "       'journal_title':Journal_title,\n",
    "         'Abstract':abstract,\n",
    "         'Journalinfo_country': Journal_Country,\n",
    "          'Published_year':year,\n",
    "           'Keyword_list':keywords,\n",
    "          'publication_type':pubtype,\n",
    "          'medline_citation':Medlinecitation,\n",
    "          \"pubmed_year\":pubmed_year,\n",
    "          \"Affiliation\":affiliation}\n",
    "\n",
    "    df =pd.DataFrame.from_dict(dict_columns, orient='index').transpose()\n",
    "    df.to_csv('../data/'+tocsv+'.csv',index=False)\n",
    "    print(\"Number of articles :\"+str(len(root)))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of records found :4250\n",
      "Number of articles :4250\n"
     ]
    }
   ],
   "source": [
    "#get_data(search_for, filename) # search anything in pubmed AND prints number of records\n",
    "get_data('convolutional neural network','pubmed_result')\n",
    "# get_dataframe(filename, tocsv) #give file name from get_data with txt extension like pubmed_result.txt and assign the function to a variable\n",
    "cnn=get_dataframe('pubmed_result.txt', 'cnn_pubmed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>Title</th>\n",
       "      <th>ISOAbbreviation</th>\n",
       "      <th>journal_title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Journalinfo_country</th>\n",
       "      <th>Published_year</th>\n",
       "      <th>Keyword_list</th>\n",
       "      <th>publication_type</th>\n",
       "      <th>medline_citation</th>\n",
       "      <th>pubmed_year</th>\n",
       "      <th>Affiliation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31710775</td>\n",
       "      <td>The Use of Optical Coherence Tomography and Co...</td>\n",
       "      <td>J Biophotonics</td>\n",
       "      <td>Journal of biophotonics</td>\n",
       "      <td>Incomplete surgical resection of head and neck...</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2019</td>\n",
       "      <td>head and neck neoplasms,margins of excision,op...</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>Publisher</td>\n",
       "      <td>2019</td>\n",
       "      <td>Beckman Laser Institute &amp; Medical Clinic, Irvi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31710668</td>\n",
       "      <td>Automatic extraction of cancer registry report...</td>\n",
       "      <td>J Am Med Inform Assoc</td>\n",
       "      <td>Journal of the American Medical Informatics As...</td>\n",
       "      <td>We implement 2 different multitask learning (M...</td>\n",
       "      <td>England</td>\n",
       "      <td>2019</td>\n",
       "      <td>cancer pathology reports,convolutional neural ...</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>Publisher</td>\n",
       "      <td>2019</td>\n",
       "      <td>Computational Sciences and Engineering Divisio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31710212</td>\n",
       "      <td>Convolutional neural networks for the design a...</td>\n",
       "      <td>J Chem Inf Model</td>\n",
       "      <td>Journal of chemical information and modeling</td>\n",
       "      <td>Convolutional neural network (CNN) is employed...</td>\n",
       "      <td>United States</td>\n",
       "      <td>2019</td>\n",
       "      <td>None</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>Publisher</td>\n",
       "      <td>2019</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31708729</td>\n",
       "      <td>Deep Learning-Based Deep Brain Stimulation Tar...</td>\n",
       "      <td>Front Neurosci</td>\n",
       "      <td>Frontiers in neuroscience</td>\n",
       "      <td>The purpose of the present study was to evalua...</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>2019</td>\n",
       "      <td>clinical application,convolutional neural netw...</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>PubMed-not-MEDLINE</td>\n",
       "      <td>2019</td>\n",
       "      <td>Department of Neurosurgery, Seoul Metropolitan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31708281</td>\n",
       "      <td>Estimating PM2.5 concentration of the contermi...</td>\n",
       "      <td>Environ. Pollut.</td>\n",
       "      <td>Environmental pollution (Barking, Essex : 1987)</td>\n",
       "      <td>We apply convolutional neural network (CNN) mo...</td>\n",
       "      <td>England</td>\n",
       "      <td>2019</td>\n",
       "      <td>Convolutional neural network (CNN),Deep learni...</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>Publisher</td>\n",
       "      <td>2019</td>\n",
       "      <td>Department of Electrical and Computer Engineer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PMID                                              Title  \\\n",
       "0  31710775  The Use of Optical Coherence Tomography and Co...   \n",
       "1  31710668  Automatic extraction of cancer registry report...   \n",
       "2  31710212  Convolutional neural networks for the design a...   \n",
       "3  31708729  Deep Learning-Based Deep Brain Stimulation Tar...   \n",
       "4  31708281  Estimating PM2.5 concentration of the contermi...   \n",
       "\n",
       "         ISOAbbreviation                                      journal_title  \\\n",
       "0         J Biophotonics                            Journal of biophotonics   \n",
       "1  J Am Med Inform Assoc  Journal of the American Medical Informatics As...   \n",
       "2       J Chem Inf Model       Journal of chemical information and modeling   \n",
       "3         Front Neurosci                          Frontiers in neuroscience   \n",
       "4       Environ. Pollut.    Environmental pollution (Barking, Essex : 1987)   \n",
       "\n",
       "                                            Abstract Journalinfo_country  \\\n",
       "0  Incomplete surgical resection of head and neck...             Germany   \n",
       "1  We implement 2 different multitask learning (M...             England   \n",
       "2  Convolutional neural network (CNN) is employed...       United States   \n",
       "3  The purpose of the present study was to evalua...         Switzerland   \n",
       "4  We apply convolutional neural network (CNN) mo...             England   \n",
       "\n",
       "  Published_year                                       Keyword_list  \\\n",
       "0           2019  head and neck neoplasms,margins of excision,op...   \n",
       "1           2019  cancer pathology reports,convolutional neural ...   \n",
       "2           2019                                               None   \n",
       "3           2019  clinical application,convolutional neural netw...   \n",
       "4           2019  Convolutional neural network (CNN),Deep learni...   \n",
       "\n",
       "  publication_type    medline_citation pubmed_year  \\\n",
       "0  Journal Article           Publisher        2019   \n",
       "1  Journal Article           Publisher        2019   \n",
       "2  Journal Article           Publisher        2019   \n",
       "3  Journal Article  PubMed-not-MEDLINE        2019   \n",
       "4  Journal Article           Publisher        2019   \n",
       "\n",
       "                                         Affiliation  \n",
       "0  Beckman Laser Institute & Medical Clinic, Irvi...  \n",
       "1  Computational Sciences and Engineering Divisio...  \n",
       "2                                                     \n",
       "3  Department of Neurosurgery, Seoul Metropolitan...  \n",
       "4  Department of Electrical and Computer Engineer...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
